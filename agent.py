import requests
import time
import os
import html
from Bio import Entrez
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
Entrez.email = "tvoj_email@example.com" 

TELEGRAM_TOKEN = os.environ.get("TG_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TG_CHAT_ID")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

HISTORY_FILE = "history.txt"
QUALITY_FILTER = " AND (Meta-Analysis[ptyp] OR Randomized Controlled Trial[ptyp] OR Systematic Review[ptyp])"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Gemini
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

RAW_QUERIES = {
    "üß¨ 1. –§—É–Ω–¥–∞–º–µ–Ω—Ç: –ú–µ—Ç–∞–±–æ–ª–∏–∑–º –∏ –î–æ–ª–≥–æ–ª–µ—Ç–∏–µ": [
        # –ú–∏—Ç–æ—Ö–æ–Ω–¥—Ä–∏–∏ –∏ –≠–Ω–µ—Ä–≥–∏—è
        "(mitochondrial biogenesis) AND (exercise) OR (zone 2)",
        "(NAD+) OR (NMN) OR (NR) AND (aging) OR (muscle performance)",
        "(AMPK activation) OR (sirtuins) AND (fasting) OR (exercise)",
        "(metabolic flexibility) AND (fat oxidation) OR (insulin sensitivity)",
        "(autophagy) AND (exercise) OR (time-restricted eating)",
        "(hormesis) AND (sauna) OR (cold exposure) OR (hypoxia)"
    ],

    "üíä 2. –ë–∏–æ—Ö–∏–º–∏—è: –ù—É—Ç—Ä–∏—Ü–µ–≤—Ç–∏–∫–∞ –∏ –ê–¥–∞–ø—Ç–æ–≥–µ–Ω—ã": [
        # –ë–∞–∑–∞
        "(creatine monohydrate) AND (brain) OR (muscle) OR (recovery)",
        "(magnesium) AND (sleep) OR (muscle relaxation) OR (stress)",
        "(omega-3) OR (fish oil) AND (inflammation) OR (recovery) OR (concussion)",
        "(vitamin D) AND (athletic performance) OR (strength) OR (testosterone)",
        
        # –≠—Ä–≥–æ–≥–µ–Ω—ã (–£—Å–∏–ª–∏—Ç–µ–ª–∏)
        "(caffeine) AND (endurance) OR (power) OR (cognitive performance)",
        "(beta-alanine) AND (high intensity) OR (tactical athlete)",
        "(nitrate) OR (beetroot juice) AND (blood flow) OR (efficiency)",
        "(ketogenic diet) OR (exogenous ketones) AND (metabolism) OR (endurance)",
        
        # –ê–¥–∞–ø—Ç–æ–≥–µ–Ω—ã (–¢—Ä–∞–≤—ã –∏ –ì—Ä–∏–±—ã)
        "(Ashwagandha) AND (cortisol) OR (strength) OR (testosterone)",
        "(Rhodiola rosea) AND (fatigue) OR (mental performance)",
        "(Lion's mane) OR (Hericium) AND (nerve growth factor) OR (cognition)",
        "(Cordyceps) AND (VO2max) OR (ATP production)",
        "(Tongkat Ali) OR (Eurycoma) AND (hormonal profile) OR (stress)",
        "(Shilajit) AND (mitochondria) OR (muscle strength)"
    ],

    "üí™ 3. –¢–µ–ª–æ: –°–∏–ª–∞, –ì–∏–ø–µ—Ä—Ç—Ä–æ—Ñ–∏—è –∏ –ú–µ—Ö–∞–Ω–∏–∫–∞": [
        # –ú—ã—à—Ü—ã
        "(hypertrophy) AND (volume) OR (frequency) OR (mechanical tension)",
        "(eccentric training) AND (tendon) OR (strength gains)",
        "(blood flow restriction) OR (BFR) AND (rehabilitation) OR (growth)",
        
        # –í–∑—Ä—ã–≤–Ω–∞—è —Å–∏–ª–∞ –∏ –ü–ª–∏–æ–º–µ—Ç—Ä–∏–∫–∞
        "(\"rate of force development\") OR (RFD) AND (explosive strength)",
        "(plyometric training) AND (sprint speed) OR (jumping)",
        "(\"stretch-shortening cycle\") AND (performance) OR (efficiency)",
        "(velocity-based training) AND (power) OR (autoregulation)",
        
        # –°–≤—è–∑–∫–∏ –∏ –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∞
        "(tendon stiffness) AND (injury prevention) OR (energy return)",
        "(mobility) OR (flexibility) AND (performance) NOT (elderly)"
    ],

    "ü´Å 4. –î–≤–∏–≥–∞—Ç–µ–ª—å: –ö–∞—Ä–¥–∏–æ –∏ –î—ã—Ö–∞–Ω–∏–µ": [
        "(VO2max) AND (longevity) OR (performance)",
        "(heart rate variability) OR (HRV) AND (recovery) OR (readiness)",
        "(stroke volume) OR (cardiac output) AND (athlete's heart)",
        "(respiratory muscle training) OR (IMT) AND (endurance) OR (breathing)",
        "(nasal breathing) OR (mouth taping) AND (sleep) OR (exercise)"
    ],

    "üß† 5. –†–∞–∑—É–º: –ù–µ–π—Ä–æ–∞—Ç–ª–µ—Ç–∏–∫–∞ –∏ –ü—Å–∏—Ö–æ–ª–æ–≥–∏—è": [
        # –ü—Å–∏—Ö–æ–ª–æ–≥–∏—è –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
        "(\"flow state\") AND (sport) OR (peak performance)",
        "(mental toughness) OR (resilience) AND (anxiety) OR (competition)",
        "(visualization) OR (motor imagery) AND (strength) OR (skill)",
        "(self-talk) AND (endurance) OR (effort perception)",
        
        # –ù–µ–π—Ä–æ—Ñ–∏–∑–∏–æ–ª–æ–≥–∏—è
        "(neuroplasticity) AND (exercise) OR (motor learning)",
        "(stroboscopic training) OR (visual training) AND (reaction time)",
        "(dopamine) AND (exercise motivation) OR (reward system)",
        "(transcranial direct current stimulation) OR (tDCS) AND (sport)"
    ],

    "üí§ 6. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ: –°–æ–Ω –∏ –†–∏—Ç–º—ã": [
        "(circadian rhythm) OR (chronotype) AND (performance)",
        "(slow wave sleep) OR (deep sleep) AND (physical recovery)",
        "(REM sleep) AND (motor memory) OR (mental health)",
        "(sleep deprivation) AND (testosterone) OR (injury risk)",
        "(glymphatic system) AND (sleep) OR (brain clearance)"
    ],

    "üçÉ 7. –°—Ä–µ–¥–∞ –∏ –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": [
        "(wearable technology) AND (accuracy) OR (load monitoring)",
        "(blue light) AND (sleep quality) OR (alertness)",
        "(grounding) OR (earthing) AND (inflammation) OR (recovery)",
        "(music) OR (binaural beats) AND (focus) OR (relaxation)",
        "(continuous glucose monitoring) AND (athlete) OR (fueling)"
    ]
}

def load_history():
    if not os.path.exists(HISTORY_FILE):
        return set()
    with open(HISTORY_FILE, "r") as f:
        return set(line.strip() for line in f)

def save_history(new_ids):
    with open(HISTORY_FILE, "a") as f:
        for pmid in new_ids:
            f.write(f"{pmid}\n")

# --- –ú–û–î–£–õ–¨ –ê–ù–ê–õ–ò–ó–ê (GEMINI) ---
def analyze_abstract_with_gemini(title, abstract):
    if not GEMINI_API_KEY:
        print("‚ùå –û–®–ò–ë–ö–ê: –ù–µ—Ç GEMINI_API_KEY")
        return "‚ö†Ô∏è –ù–µ—Ç –∫–ª—é—á–∞ Gemini"

    prompt = f"""
    You are a sports physiologist. Analyze this abstract.
    Title: {title}
    Abstract: {abstract}
    
    Task:
    1. Summarize the key finding in ONE sentence in RUSSIAN.
    2. Format: "‚úÖ [Action/Supplement] on [Subjects] -> [Result] (change % or value)."
    """

    # –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –°–ü–ò–°–û–ö –ú–û–î–ï–õ–ï–ô
    # –£–±—Ä–∞–ª–∏ —Å—Ç–∞—Ä—É—é 'gemini-pro', –æ—Å—Ç–∞–≤–∏–ª–∏ —Ç–æ–ª—å–∫–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ 1.5
    models_to_try = ['gemini-1.5-flash', 'gemini-1.5-pro']

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (—Ä–∞–∑—Ä–µ—à–∞–µ–º –≤—Å—ë, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ—á–∏–ª–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã)
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    last_error = ""

    for model_name in models_to_try:
        try:
            # print(f"üîç –ü—Ä–æ–±—É–µ–º –º–æ–¥–µ–ª—å: {model_name}...") # –ú–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            model = genai.GenerativeModel(model_name)
            
            response = model.generate_content(
                prompt, 
                safety_settings=safety_settings
            )
            
            if response.text:
                return response.text.strip()
            
        except Exception as e:
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞, –º–æ–ª—á–∞ –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é
            last_error = str(e)
            continue
    
    # –ï—Å–ª–∏ –ø–µ—Ä–µ–ø—Ä–æ–±–æ–≤–∞–ª–∏ –≤—Å–µ –∏ –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã—à–ª–æ
    return f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title} (–û—à–∏–±–∫–∞ AI: {last_error})"
    
# --- –ü–û–ò–°–ö ---
def search_pubmed(query, days=None, retmax=5, sort="date"):
    full_query = query + QUALITY_FILTER
    try:
        params = {"db": "pubmed", "term": full_query, "retmax": retmax, "sort": sort}
        if days:
            params["reldate"] = days
            params["datetype"] = "pdat"
        handle = Entrez.esearch(**params)
        record = Entrez.read(handle)
        handle.close()
        return record["IdList"]
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
        return []

def fetch_details_and_analyze(id_list):
    if not id_list: return []
    ids = ",".join(id_list)
    try:
        handle = Entrez.efetch(db="pubmed", id=ids, retmode="xml")
        records = Entrez.read(handle)
        handle.close()
        papers = []
        for article in records['PubmedArticle']:
            try:
                pmid = article['MedlineCitation']['PMID']
                title_en = article['MedlineCitation']['Article']['ArticleTitle']
                
                abstract_parts = article['MedlineCitation']['Article'].get('Abstract', {}).get('AbstractText', [])
                full_abstract = " ".join(abstract_parts) if abstract_parts else ""

                if not full_abstract:
                    summary = f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title_en} (–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏)"
                else:
                    summary = analyze_abstract_with_gemini(title_en, full_abstract)
                
                link = f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/"
                pub_date = article['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']
                year = pub_date.get('Year', 'N/A')
                
                papers.append({'summary': summary, 'link': link, 'id': str(pmid), 'year': year})
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —Å—Ç–∞—Ç—å–∏ {pmid}: {e}")
                continue
        return papers
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
        return []

# --- TELEGRAM ---
def send_telegram_message(message):
    if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
        print("‚ùå –¢–æ–∫–µ–Ω—ã –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    data = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "HTML", "disable_web_page_preview": True}
    requests.post(url, data=data)

# --- MAIN ---
def main():
    print("–ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ v3.3 (DEBUG MODE)...")
    
    seen_ids = load_history()
    all_papers = []
    new_seen_ids = []

    # 1. –°–≤–µ–∂–µ–µ
    print("–≠—Ç–∞–ø 1: –ü–æ–∏—Å–∫ —Å–≤–µ–∂–∏—Ö...")
    for category, query_list in RAW_QUERIES.items():
        for q in query_list:
            ids = search_pubmed(q, days=1, retmax=1) # –ë–µ—Ä–µ–º –ø–æ 1 –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
            unique_ids = [i for i in ids if i not in seen_ids]
            if unique_ids:
                details = fetch_details_and_analyze(unique_ids)
                for paper in details:
                    paper['category'] = category
                    paper['type'] = 'fresh'
                    all_papers.append(paper)
                    seen_ids.add(paper['id'])
                    new_seen_ids.append(paper['id'])
            time.sleep(1)

    # 2. –ê—Ä—Ö–∏–≤
    if len(all_papers) < 5:
        print("–≠—Ç–∞–ø 2: –ü–æ–∏—Å–∫ –≤ –∞—Ä—Ö–∏–≤–µ...")
        needed = 5 - len(all_papers)
        for category, query_list in RAW_QUERIES.items():
            if needed <= 0: break
            for q in query_list:
                ids = search_pubmed(q, days=1825, retmax=5, sort="relevance")
                candidates = [i for i in ids if i not in seen_ids]
                if candidates:
                    to_take = candidates[:1]
                    details = fetch_details_and_analyze(to_take)
                    for paper in details:
                        paper['category'] = category
                        paper['type'] = 'archive'
                        all_papers.append(paper)
                        seen_ids.add(paper['id'])
                        new_seen_ids.append(paper['id'])
                        needed -= 1
                time.sleep(1)

    if not all_papers:
        print("–ù–∏—á–µ–≥–æ –Ω–æ–≤–æ–≥–æ.")
        return

    all_papers.sort(key=lambda x: x['type'], reverse=True)

    # 3. –û–¢–ü–†–ê–í–ö–ê
    buffer_message = "<b>üß† Biohack Digest (DEBUG)</b>\n\n"
    current_category = ""
    
    for paper in all_papers:
        article_text = ""
        if paper['category'] != current_category:
            article_text += f"<b>üîπ {paper['category']}</b>\n"
            current_category = paper['category']
        
        icon = "‚ö°Ô∏è" if paper['type'] == 'fresh' else "üî¨"
        
        clean_summary = html.escape(paper['summary'])
        clean_summary = clean_summary.replace("**", "").replace("##", "")
        
        article_text += f"{icon} <a href='{paper['link']}'>–ò—Å—Ç–æ—á–Ω–∏–∫</a> ({paper['year']})\n{clean_summary}\n\n"
        
        if len(buffer_message) + len(article_text) > 3000:
            send_telegram_message(buffer_message)
            buffer_message = article_text
        else:
            buffer_message += article_text

    if buffer_message:
        send_telegram_message(buffer_message)

    if new_seen_ids:
        save_history(new_seen_ids)

if __name__ == "__main__":
    main()
